{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MNIST 손글씨 분류기 - PyTorch, MLflow\n","- Fashion MNIST 이미지 분류 작업을 통해 PyTorch를 사용한 MLflow의 기능을 시연해 보겠습니다.  \n","  - 이미지 분류기로서 컨볼루션 신경망을 구축하고 다음 정보를 mlflow에 기록합니다:  \n","  - 훈련 지표: 훈련 손실 및 정확도.\n","  - 평가 지표: 평가 손실 및 정확도.\n","  - 훈련 설정: 학습 속도, 배치 크기 등.\n","  - 모델 정보: 모델 구조.\n","  - 저장된 모델: 학습 후 모델 인스턴스.\n","\n","  \n","\n","- 출처 : https://mlflow.org/docs/latest/deep-learning/pytorch/quickstart/pytorch_quickstart.html"]},{"cell_type":"markdown","metadata":{},"source":["### 패키지 설치"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -q mlflow torchmetrics torchinfo"]},{"cell_type":"markdown","metadata":{},"source":["##"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchinfo import summary\n","from torchmetrics import Accuracy\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import mlflow"]},{"cell_type":"markdown","metadata":{},"source":["#### 데이터 준비하기 \n","이미 [0, 1]의 스케일로 사전 처리된 훈련 데이터 FashionMNIST를 torchvision에서 로드해 보겠습니다.   \n","그런 다음 데이터 세트를 torch.utils.data.Dataloader의 인스턴스로 래핑합니다.  "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Image size: torch.Size([1, 28, 28])\n","Size of training dataset: 60000\n","Size of test dataset: 10000\n"]}],"source":["print(f\"Image size: {training_data[0][0].shape}\")\n","print(f\"Size of training dataset: {len(training_data)}\")\n","print(f\"Size of test dataset: {len(test_data)}\")"]},{"cell_type":"markdown","metadata":{},"source":["배치 처리를 위해 데이터 집합을 DataLoader 인스턴스로 래핑합니다.   \n","DataLoader는 데이터 전처리를 위한 유용한 도구입니다.   "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["train_dataloader = DataLoader(training_data, batch_size=64)\n","test_dataloader = DataLoader(test_data, batch_size=64)"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 정의하기\n","- PyTorch 모델을 정의하려면 torch.nn.Module에서 서브클래싱하고 __init__를 재정의하여 모델 구성 요소를 정의하고 forward() 메서드를 재정의하여 정방향 전달 로직을 구현해야 합니다.\n","- 이미지 분류기로 2개의 컨볼루션 레이어로 구성된 간단한 컨볼루션 신경망(CNN)을 구축하겠습니다. \n","- 모델 출력은 각 클래스(총 10개 클래스)의 로짓이 됩니다. \n","- 로짓에 소프트맥스를 적용하면 클래스 간 확률 분포가 산출됩니다."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class ImageClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 8, kernel_size=3),\n","            nn.ReLU(),\n","            nn.Conv2d(8, 16, kernel_size=3),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.LazyLinear(10),  # 10 classes in total.\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["<Experiment: artifact_location='file:///d:/%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C/MLflow/code/mlruns/581093473327566797', creation_time=1710547283371, experiment_id='581093473327566797', last_update_time=1710547283371, lifecycle_stage='active', name='mlflow-pytorch-quickstart', tags={}>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["mlflow.set_experiment(\"mlflow-pytorch-quickstart\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training Loop 구현\n","이제 기본적으로 데이터 집합을 반복하고 각 데이터 배치에 정방향 및 역방향 패스를 적용하는 학습 루프를 정의해 보겠습니다."]},{"cell_type":"markdown","metadata":{},"source":["PyTorch는 수동 device 관리가 필요하므로 device 정보를 가져옵니다."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Get cpu or gpu for training.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{},"source":["#### 트레이닝 함수를 정의합니다."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n","    \"\"\"Train the model on a single pass of the dataloader.\n","\n","    Args:\n","        dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n","        model: an instance of `torch.nn.Module`, the model to be trained.\n","        loss_fn: a callable, the loss function.\n","        metrics_fn: a callable, the metrics function.\n","        optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n","        epoch: an integer, the current epoch number.\n","    \"\"\"\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        accuracy = metrics_fn(pred, y)\n","\n","        # Backpropagation.\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch\n","            step = batch // 100 * (epoch + 1)\n","            mlflow.log_metric(\"loss\", f\"{loss:2f}\", step=step)\n","            mlflow.log_metric(\"accuracy\", f\"{accuracy:2f}\", step=step)\n","            print(\n","                f\"loss: {loss:2f} accuracy: {accuracy:2f} [{current} / {len(dataloader)}]\"\n","            )"]},{"cell_type":"markdown","metadata":{},"source":["#### 각 에포크가 끝날 때 실행될 평가 함수를 정의합니다."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n","    \"\"\"Evaluate the model on a single pass of the dataloader.\n","\n","    Args:\n","        dataloader: an instance of `torch.utils.data.DataLoader`, containing the eval data.\n","        model: an instance of `torch.nn.Module`, the model to be trained.\n","        loss_fn: a callable, the loss function.\n","        metrics_fn: a callable, the metrics function.\n","        epoch: an integer, the current epoch number.\n","    \"\"\"\n","    num_batches = len(dataloader)\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            eval_loss += loss_fn(pred, y).item()\n","            eval_accuracy += metrics_fn(pred, y)\n","\n","    eval_loss /= num_batches\n","    eval_accuracy /= num_batches\n","    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epoch)\n","    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:2f}\", step=epoch)\n","\n","    print(f\"Eval metrics: \\nAccuracy: {eval_accuracy:.2f}, Avg loss: {eval_loss:2f} \\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n","epochs 하이퍼 파라미터를 정의하고, 손실 함수를 선언하고, 모델을 생성하고,  optimizer를 인스턴스화 합니다."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["epochs = 3\n","loss_fn = nn.CrossEntropyLoss()\n","metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n","model = ImageClassifier().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"]},{"cell_type":"markdown","metadata":{},"source":["모든 것을 종합하여 훈련을 시작하고 MLflow에 정보를 기록해 보겠습니다.   \n","훈련 시작 시에는 훈련 및 모델 정보를 MLflow에 기록하고, 훈련 중에는 훈련 및 평가 메트릭을 기록합니다.   \n","모든 작업이 완료되면 학습된 모델을 기록합니다.  "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.301674 accuracy: 0.031250 [0 / 938]\n","loss: 2.274231 accuracy: 0.109375 [100 / 938]\n","loss: 2.219673 accuracy: 0.265625 [200 / 938]\n","loss: 2.158956 accuracy: 0.421875 [300 / 938]\n","loss: 1.950855 accuracy: 0.562500 [400 / 938]\n","loss: 1.593455 accuracy: 0.656250 [500 / 938]\n","loss: 1.280893 accuracy: 0.656250 [600 / 938]\n","loss: 0.988957 accuracy: 0.765625 [700 / 938]\n","loss: 0.931154 accuracy: 0.718750 [800 / 938]\n","loss: 0.876485 accuracy: 0.734375 [900 / 938]\n","Eval metrics: \n","Accuracy: 0.72, Avg loss: 0.804336 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.776549 accuracy: 0.765625 [0 / 938]\n","loss: 0.845168 accuracy: 0.703125 [100 / 938]\n","loss: 0.548310 accuracy: 0.843750 [200 / 938]\n","loss: 0.819213 accuracy: 0.687500 [300 / 938]\n","loss: 0.704526 accuracy: 0.671875 [400 / 938]\n","loss: 0.704366 accuracy: 0.781250 [500 / 938]\n","loss: 0.732565 accuracy: 0.718750 [600 / 938]\n","loss: 0.659362 accuracy: 0.765625 [700 / 938]\n","loss: 0.697894 accuracy: 0.718750 [800 / 938]\n","loss: 0.700490 accuracy: 0.750000 [900 / 938]\n","Eval metrics: \n","Accuracy: 0.77, Avg loss: 0.648501 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.543282 accuracy: 0.828125 [0 / 938]\n","loss: 0.666583 accuracy: 0.734375 [100 / 938]\n","loss: 0.433046 accuracy: 0.828125 [200 / 938]\n","loss: 0.705230 accuracy: 0.750000 [300 / 938]\n","loss: 0.645952 accuracy: 0.703125 [400 / 938]\n","loss: 0.645345 accuracy: 0.796875 [500 / 938]\n","loss: 0.651277 accuracy: 0.734375 [600 / 938]\n","loss: 0.638427 accuracy: 0.796875 [700 / 938]\n","loss: 0.691399 accuracy: 0.718750 [800 / 938]\n","loss: 0.611050 accuracy: 0.734375 [900 / 938]\n","Eval metrics: \n","Accuracy: 0.77, Avg loss: 0.615661 \n","\n"]}],"source":["with mlflow.start_run() as run:\n","    params = {\n","        \"epochs\": epochs,\n","        \"learning_rate\": 1e-3,\n","        \"batch_size\": 64,\n","        \"loss_function\": loss_fn.__class__.__name__,\n","        \"metric_function\": metric_fn.__class__.__name__,\n","        \"optimizer\": \"SGD\",\n","    }\n","    # Log training parameters.\n","    mlflow.log_params(params)\n","\n","    # Log model summary.\n","    with open(\"model_summary.txt\", \"w\") as f:\n","        f.write(str(summary(model)))\n","    mlflow.log_artifact(\"model_summary.txt\")\n","\n","    for t in range(epochs):\n","        print(f\"Epoch {t+1}\\n-------------------------------\")\n","        train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\n","        evaluate(test_dataloader, model, loss_fn, metric_fn, epoch=0)\n","\n","    # Save the trained model to MLflow.\n","    mlflow.pytorch.log_model(model, \"model\")"]},{"cell_type":"markdown","metadata":{},"source":["마지막 단계로 모델을 다시 로드하고 추론을 실행해 보겠습니다."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["logged_model = f\"runs:/{run.info.run_id}/model\"\n","loaded_model = mlflow.pyfunc.load_model(logged_model)"]},{"cell_type":"markdown","metadata":{},"source":["로드된 모델에 대한 입력은 numpy array 또는 pandas Dataframe이어야 하므로, tensor 를 명시적으로 numpy format 으로 캐스팅해야 합니다."]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["outputs = loaded_model.predict(training_data[0][0][None, :].numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN8PAXFnFKeHTQH/H+w094E","collapsed_sections":[],"name":"2장.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
